{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-mqvLZeTfzNv"
      },
      "outputs": [],
      "source": [
        "import utils\n",
        "\n",
        "# Get the default financial and AC Model parameters\n",
        "financial_params, ac_params = utils.get_env_param()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "financial_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "COox5pgraahZ",
        "outputId": "9a810c92-7c74-491f-e1ad-5d8190a09e5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Financial Parameters</caption>\n",
              "<tr>\n",
              "  <th>Annual Volatility:</th>  <td>12%</td> <th>  Bid-Ask Spread:    </th>     <td>0.125</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Daily Volatility:</th>  <td>0.8%</td> <th>  Daily Trading Volume:</th> <td>5,000,000</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Annual Volatility:} &  12\\% & \\textbf{  Bid-Ask Spread:    }   &   0.125    \\\\\n\\textbf{Daily Volatility:}  & 0.8\\% & \\textbf{  Daily Trading Volume:} & 5,000,000  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{Financial Parameters}\n\\end{center}"
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ac_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "flj1ri3jaheo",
        "outputId": "21db04f3-f91f-4a18-d066-47f3e2d8438b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.table.SimpleTable'>"
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>Almgren and Chriss Model Parameters</caption>\n",
              "<tr>\n",
              "  <th>Total Number of Shares to Sell:</th>                  <td>1,000,000</td> <th>  Fixed Cost of Selling per Share:</th> <td>$0.062</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Starting Price per Share:</th>                         <td>$50.00</td>   <th>  Trader's Risk Aversion:</th>           <td>1e-06</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Price Impact for Each 1% of Daily Volume Traded:</th> <td>$2.5e-06</td>  <th>  Permanent Impact Constant:</th>       <td>2.5e-07</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Days to Sell All the Shares:</th>              <td>60</td>     <th>  Single Step Variance:</th>             <td>0.144</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Number of Trades:</th>                                   <td>60</td>     <th>  Time Interval between trades:</th>      <td>1.0</td>  \n",
              "</tr>\n",
              "</table>"
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Total Number of Shares to Sell:}                   & 1,000,000 & \\textbf{  Fixed Cost of Selling per Share:} & \\$0.062  \\\\\n\\textbf{Starting Price per Share:}                         &  \\$50.00  & \\textbf{  Trader's Risk Aversion:}          &  1e-06   \\\\\n\\textbf{Price Impact for Each 1\\% of Daily Volume Traded:} & \\$2.5e-06 & \\textbf{  Permanent Impact Constant:}       & 2.5e-07  \\\\\n\\textbf{Number of Days to Sell All the Shares:}            &     60    & \\textbf{  Single Step Variance:}            &  0.144   \\\\\n\\textbf{Number of Trades:}                                 &     60    & \\textbf{  Time Interval between trades:}    &   1.0    \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{Almgren and Chriss Model Parameters}\n\\end{center}"
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import importlib\n",
        "import syntheticChrissAlmgren as sca\n",
        "importlib.reload(sca)\n",
        "import ddpg_agent\n",
        "from ddpg_agent import Agent\n",
        "\n",
        "from collections import deque\n",
        "\n",
        "def test_agent(use_custom_reward, sparse_reward):\n",
        "    # Create simulation environment\n",
        "    env = sca.MarketEnvironment()\n",
        "\n",
        "    # Initialize Feed-forward DNNs for Actor and Critic models.\n",
        "    agent = Agent(state_size=env.observation_space_dimension(), action_size=env.action_space_dimension(), random_seed=0)\n",
        "\n",
        "    # Set the liquidation time\n",
        "    lqt = 60\n",
        "\n",
        "    # Set the number of trades\n",
        "    n_trades = 60\n",
        "\n",
        "    # Set trader's risk aversion\n",
        "    tr = 1e-6\n",
        "\n",
        "    # Set the number of episodes to run the simulation\n",
        "    episodes = 1000\n",
        "\n",
        "    shortfall_hist = np.array([])\n",
        "    shortfall_deque = deque(maxlen=100)\n",
        "\n",
        "    for episode in range(episodes):\n",
        "        # Reset the enviroment\n",
        "        cur_state = env.reset(seed=episode, liquid_time=lqt, num_trades=n_trades, lamb=tr, use_custom_reward=use_custom_reward, sparse_reward=sparse_reward)\n",
        "\n",
        "\n",
        "        # set the environment to make transactions\n",
        "        env.start_transactions()\n",
        "\n",
        "        for i in range(n_trades + 1):\n",
        "\n",
        "            # Predict the best action for the current state.\n",
        "            action = agent.act(cur_state, add_noise = True)\n",
        "\n",
        "            # Action is performed and new state, reward, info are received.\n",
        "            new_state, reward, done, info = env.step(action)\n",
        "\n",
        "            # current state, action, reward, new state are stored in the experience replay\n",
        "            agent.step(cur_state, action, reward, new_state, done)\n",
        "\n",
        "            # roll over new state\n",
        "            cur_state = new_state\n",
        "\n",
        "            if info.done:\n",
        "                shortfall_hist = np.append(shortfall_hist, info.implementation_shortfall)\n",
        "                shortfall_deque.append(info.implementation_shortfall)\n",
        "                break\n",
        "\n",
        "\n",
        "    print(f'\\nAverage Implementation Shortfall for sparse_reward={sparse_reward}: ${np.mean(shortfall_hist):,.2f} \\n')\n",
        "\n",
        "\n",
        "# Dense reward (normal case)\n",
        "test_agent(use_custom_reward=True, sparse_reward=False)\n",
        "\n",
        "# Sparse reward (only at end)\n",
        "test_agent(use_custom_reward=True, sparse_reward=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0Z8XsTfami4",
        "outputId": "e769a5aa-046f-4e8b-9862-a72caf2bbdff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Implementation Shortfall for sparse_reward=False: $2,483,291.89 \n",
            "\n",
            "\n",
            "Average Implementation Shortfall for sparse_reward=True: $2,534,694.13 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Todo\n",
        "\n",
        "The above code should provide you with a starting framework for incorporating more complex dynamics into our model. Here are a few things you can try out:\n",
        "\n",
        "- Explain why log-returns in a time window of 6 periods, along with $m_k$ and $i_k$ is a good choice for the state? Could you expand or shrink $D$ = number of past log-returns (which is considered $D=5$) to get better results?\n",
        "\n",
        "- Incorporate your own reward function in the simulation environmet to see if you can achieve a expected shortfall that is better (lower) than that produced by the Almgren and Chriss model.\n",
        "\n",
        "\n",
        "- Experiment rewarding the agent at every step and only giving a reward at the end. Which is; what happens if the reward function is sparse?\n",
        "\n",
        "\n",
        "- Use more realistic price dynamics, such as geometric brownian motion (GBM). The equations used to model GBM can be found in section 3b of paper: GBM\n",
        "\n",
        "\n",
        "- Try different functions for the action. You can change the values of the actions produced by the agent by using different functions. You can choose your function depending on the interpretation you give to the action. For example, you could set the action to be a **function of the trading rate**.\n",
        "\n",
        "\n",
        "- Add more complex dynamics to the environment. Try incorporate trading fees, for example. This can be done by adding and extra term to the fixed cost of selling, $\\epsilon$.\n",
        "\n",
        "- Use SAC (soft actor-critic) and TD3 (Twin Delayed Deep Deterministic) with different hyperparameters and network structures to compare your results to DDPG results. Explain why this happens."
      ],
      "metadata": {
        "id": "CtU8RqMFcYeU"
      }
    }
  ]
}